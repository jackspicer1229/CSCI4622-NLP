{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#includes downloads for necessary nltk components\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('Digital_Music_5.json.gz','rb') as f:\n",
    "    review_frame = pd.read_json(f, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "4001\n",
      "548\n"
     ]
    }
   ],
   "source": [
    "# separate all reviews by rating\n",
    "reviews_1 = review_frame[review_frame['overall'] == 1][[\"reviewText\",\"overall\"]]\n",
    "reviews_2 = review_frame[review_frame['overall'] == 2][[\"reviewText\",\"overall\"]]\n",
    "reviews_3 = review_frame[review_frame['overall'] == 3][[\"reviewText\",\"overall\"]]\n",
    "reviews_4 = review_frame[review_frame['overall'] == 4][[\"reviewText\",\"overall\"]]\n",
    "reviews_5 = review_frame[review_frame['overall'] == 5][[\"reviewText\",\"overall\"]]\n",
    "\n",
    "#now that we're down to 2 columns, clean the data set\n",
    "reviews_1 = reviews_1.dropna()\n",
    "reviews_2 = reviews_2.dropna()\n",
    "reviews_3 = reviews_3.dropna()\n",
    "reviews_4 = reviews_4.dropna()\n",
    "reviews_5 = reviews_5.dropna()\n",
    "\n",
    "#split into training and test samples:\n",
    "split1 = train_test_split(reviews_1[\"reviewText\"], reviews_1[\"overall\"])\n",
    "split2 = train_test_split(reviews_2[\"reviewText\"], reviews_2[\"overall\"])\n",
    "split3 = train_test_split(reviews_3[\"reviewText\"], reviews_3[\"overall\"])\n",
    "split4 = train_test_split(reviews_4[\"reviewText\"], reviews_4[\"overall\"])\n",
    "split5 = train_test_split(reviews_5[\"reviewText\"], reviews_5[\"overall\"])\n",
    "#consolidate training and test examples into two arrays each\n",
    "#X_train = pd.concat([split1[0],split2[0], split3[0], split4[0],split5[0]])\n",
    "#X_test = pd.concat([split1[1],split2[1], split3[1], split4[1],split5[1]])\n",
    "#y_train = pd.concat([split1[2],split2[2], split3[2], split4[2],split5[2]])\n",
    "#y_test = pd.concat([split1[3],split2[3], split3[3], split4[3],split5[3]])\n",
    "\n",
    "\n",
    "#same as above; shorter dataset\n",
    "X_train = pd.concat([split1[0][0:1000],split2[0][0:1000], split3[0][0:1000], split4[0][0:1000],split5[0][0:1000]])\n",
    "X_test = pd.concat([split1[1][0:1000],split2[1][0:1000], split3[1][0:1000], split4[1][0:1000],split5[1][0:1000]])\n",
    "y_train = pd.concat([split1[2][0:1000],split2[2][0:1000], split3[2][0:1000], split4[2][0:1000],split5[2][0:1000]])\n",
    "y_test = pd.concat([split1[3][0:1000],split2[3][0:1000], split3[3][0:1000], split4[3][0:1000],split5[3][0:1000]])\n",
    "\n",
    "\n",
    "#featurizing input text\n",
    "def extract_features(text):\n",
    "    #if word_tokenize is given bad input, the error message is fairly cryptic\n",
    "    #This was written while troubleshooting; the error doesn't occur for the original dataset\n",
    "    if not isinstance(text, str):\n",
    "        assert False, text\n",
    "    else:\n",
    "        tokenized = nltk.word_tokenize(text) #tokenizing review text\n",
    "        classified = nltk.pos_tag(tokenized, tagset='universal')\n",
    "        _, tags = zip(*classified) #pos_tag returns a list of tuples (word,tag); unzipping this list to count\n",
    "\n",
    "        #refer to section 2.3 of http://www.nltk.org/book/ch05.html for information on tags\n",
    "\n",
    "        verb_ct = tags.count(\"VERB\")\n",
    "        noun_ct = tags.count(\"NOUN\")\n",
    "        adj_ct = tags.count(\"ADJ\")\n",
    "        punc_ct = tags.count(\".\")\n",
    "        badwd_ct = tags.count(\"X\")\n",
    "        word_ct = len(tokenized) - punc_ct\n",
    "        if word_ct == 0:\n",
    "            av_word_len = 0 #prevents divide by 0 errors\n",
    "        else:\n",
    "            av_word_len = (len(text)-word_ct-punc_ct+1)/word_ct\n",
    "        #the av_word_len calculation is an approximation\n",
    "\n",
    "        return [verb_ct, noun_ct, adj_ct, punc_ct, badwd_ct, word_ct, av_word_len]\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 training examples featurized\n",
      "5000 total training examples complete\n",
      "0 test examples featurized\n",
      "4001 total test examples complete\n"
     ]
    }
   ],
   "source": [
    "#featurizing training data\n",
    "#(this may take 30-45 seconds per 10,000 reviews)\n",
    "\n",
    "X_train_featurized = []\n",
    "ctr = -1\n",
    "broken_review = \"\"\n",
    "for train_text in X_train:\n",
    "    broken_review = train_text\n",
    "    X_train_featurized.append(extract_features(train_text))\n",
    "    ctr+=1\n",
    "    if ctr%10000 == 0:\n",
    "        print(ctr,\"training examples featurized\")\n",
    "\n",
    "#featurizing test data\n",
    "\n",
    "print(len(X_train_featurized), \"total training examples complete\")\n",
    "\n",
    "X_test_featurized = []\n",
    "ctr = -1\n",
    "for test_ex in X_test:\n",
    "    X_test_featurized.append(extract_features(test_ex))\n",
    "    ctr+=1\n",
    "    if ctr%10000 == 0:\n",
    "        print(ctr,\"test examples featurized\")\n",
    "\n",
    "print(len(X_test_featurized), \"total test examples complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000\n",
      "4001 4001\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#sanity check--should have equal numbers of data points and classes\n",
    "print(len(X_train_featurized), len(y_train))\n",
    "print(len(X_test_featurized), len(y_test))\n",
    "print(len(X_test_featurized[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regenerates data for binary classifier\n",
    "y_train_bin = y_train.apply(lambda x: 1 if x>3 else  0)\n",
    "y_test_bin = y_test.apply(lambda x: 1 if x>3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#fitting linear model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train_featurized, y_train_bin)\n",
    "\n",
    "\n",
    "mean_test_score = logreg.score(X_test_featurized, y_test_bin)\n",
    "print(\"test accuracy: {:.3f}\".format(mean_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416\n",
      "548\n",
      "4001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1855,  146],\n",
       "       [1730,  270]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(logreg.predict(X_test_featurized)).count(1))\n",
    "print(list(y_test).count(1))\n",
    "print(len(X_test_featurized))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test_predicted = logreg.predict(X_test_featurized)\n",
    "confusion_matrix(y_test_bin, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[230 135  72  51  60]\n",
      " [ 72 215  71  38  57]\n",
      " [126 272 351 128 123]\n",
      " [147 234 196 211 212]\n",
      " [159 176 181 168 316]]\n",
      "0.3306673331667083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#running SVC on 5 class data\n",
    "nlsvm = SVC(kernel='rbf', gamma=.1, C = 1e4, max_iter=1000000).fit(X_train_featurized, y_train)\n",
    "y_test_predicted = nlsvm.predict(X_test_featurized)\n",
    "a = confusion_matrix(y_test, y_test_predicted)\n",
    "print(a)\n",
    "print(np.trace(a)/np.sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1441  560]\n",
      " [ 942 1058]]\n",
      "0.6245938515371158\n"
     ]
    }
   ],
   "source": [
    "#running SVC for binary classification\n",
    "nlsvm2 = SVC(kernel='rbf', gamma=.1, C = 1e4, max_iter=10000000).fit(X_train_featurized, y_train_bin)\n",
    "y_test_predicted = nlsvm2.predict(X_test_featurized)\n",
    "a = confusion_matrix(y_test_bin, y_test_predicted)\n",
    "print(a)\n",
    "print(np.trace(a)/np.sum(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
